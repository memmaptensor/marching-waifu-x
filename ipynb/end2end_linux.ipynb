{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `setup.sh` (once) beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Setup torch and other prerequisites\n",
    "%cd ../\n",
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install gdown ipykernel ipywidgets\n",
    "!python -m pip install torch torchvision torchaudio torchtext torchdata --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Update submodules\n",
    "!git submodule update --init --recursive\n",
    "\n",
    "# Create directories\n",
    "!mkdir data/dataset/nerf/original/\n",
    "!mkdir data/dataset/nerf/train/\n",
    "\n",
    "# Install requirements\n",
    "!python -m pip install -r requirements.txt\n",
    "\n",
    "# Setup RealESRGAN\n",
    "%cd ext/Real-ESRGAN/\n",
    "!python -m pip install -r requirements.txt\n",
    "!python setup.py develop\n",
    "%cd ../../\n",
    "\n",
    "# Setup SegmentAnything, GroundingDINO\n",
    "%cd ext/Grounded-Segment-Anything/\n",
    "!python -m pip install -e segment_anything\n",
    "!python -m pip install -e GroundingDINO\n",
    "%cd grounded-sam-osx\n",
    "!python -m pip install openmim\n",
    "!mim install mmcv-full\n",
    "!python -m pip install -r requirements.txt\n",
    "%cd transformer_utils\n",
    "!python setup.py install\n",
    "%cd ../../../../\n",
    "!python -m pip install timm transformers fairscale pycocoevalcap scipy\n",
    "!python -m pip install pycocotools onnxruntime onnx\n",
    "\n",
    "# Setup InstantNGP\n",
    "!apt install libgoogle-glog-dev \\\n",
    "    libgflags-dev \\\n",
    "    libatlas-base-dev \\\n",
    "    libeigen3-dev \\\n",
    "    libsuitesparse-dev \\\n",
    "    libboost-program-options-dev \\\n",
    "    libboost-filesystem-dev \\\n",
    "    libboost-graph-dev \\\n",
    "    libboost-system-dev \\\n",
    "    libboost-test-dev \\\n",
    "    libfreeimage-dev \\\n",
    "    libmetis-dev \\\n",
    "    libglew-dev \\\n",
    "    qtbase5-dev \\\n",
    "    libqt5opengl5-dev \\\n",
    "    libcgal-dev\n",
    "!pip install commentjson\n",
    "%cd data/\n",
    "!wget https://github.com/camenduru/instant-ngp-colab/releases/download/v1.0/ceres-solver-v2.zip\n",
    "!wget https://github.com/camenduru/instant-ngp-colab/releases/download/v1.0/instant-ngp-v2.zip\n",
    "!unzip ceres-solver-v2.zip -d ceres-solver\n",
    "!unzip instant-ngp-v2.zip -d instant-ngp\n",
    "!rm ceres-solver-v2.zip\n",
    "!rm instant-ngp-v2.zip\n",
    "!cp -r ceres-solver/lib/. /usr/local/lib\n",
    "!chmod 755 ceres-solver/bin/colmap\n",
    "!cp -r ceres-solver/bin/. /usr/local/bin\n",
    "%cd ../"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%cd scripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import PIL.Image\n",
    "from IPython.display import Video\n",
    "\n",
    "from src.utils.image_wrapper import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ControlVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video(fps, images, scale, video_path, fourcc):\n",
    "    images = [image_wrapper(image).scale(scale).to_cv2() for image in images]\n",
    "    video = cv2.VideoWriter(video_path, fourcc, fps, images[0].size)\n",
    "    for image in images:\n",
    "        video.write(image)\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def display_video(video_path):\n",
    "    Video.from_file(video_path, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlvideo_conf = \"\"\"\n",
    "{\n",
    "    \"paths\": {\n",
    "        \"out_path\": \"../data/dataset/nerf/original/\",\n",
    "        \"cache_dir\": \"../data/checkpoints/\",\n",
    "        \"ifnet_path\": \"../data/checkpoints/flownet.pkl\",\n",
    "        \"condition_path\": \"../data/dataset/conditioning/\",\n",
    "        \"textual_inversion_path\": \"../data/embeddings/\"\n",
    "    },\n",
    "    \"repositories\": {\n",
    "        \"sd\": \"rossiyareich/aniflatmixAnimeFlatColorStyle_v20-fp16\",\n",
    "        \"vae\": \"rossiyareich/anything-v4.0-vae\"\n",
    "    },\n",
    "    \"controlnet\": {\n",
    "        \"scales\": [1.0, 0.85, 0.85, 0.70],\n",
    "        \"exp\": 0.85,\n",
    "        \"pipe\": {\n",
    "            \"openpose_full\": \"lllyasviel/control_v11p_sd15_openpose\",\n",
    "            \"depth\": \"lllyasviel/control_v11f1p_sd15_depth\",\n",
    "            \"normals\": \"lllyasviel/control_v11p_sd15_normalbae\",\n",
    "            \"lineart\": \"lllyasviel/control_v11p_sd15_lineart\"\n",
    "        }\n",
    "    },\n",
    "    \"video\": {\n",
    "        \"num_inference_steps\": 20,\n",
    "        \"guidance_scale\": 8.0,\n",
    "        \"smooth_steps\": [14, 15],\n",
    "        \"seed\": null,\n",
    "        \"same_frame_noise\": false,\n",
    "        \"length\": 64,\n",
    "        \"keyframes\": {\n",
    "            \"frames\": [0, 7, 15, 23, 31, 39, 47, 55, 63],\n",
    "            \"prompt\": \"(masterpiece, best quality)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "            \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "        },\n",
    "        \"clips\": [\n",
    "            {\n",
    "                \"attn_frames\": [0, 7],\n",
    "                \"clip_frames\": [1, 2, 3, 4, 5, 6],\n",
    "                \"prompt\": \"(masterpiece, best quality, anime screencap, front view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            },\n",
    "            {\n",
    "                \"attn_frames\": [7, 15],\n",
    "                \"clip_frames\": [8, 9, 10, 11, 12, 13, 14],\n",
    "                \"prompt\": \"(masterpiece, best quality, anime screencap, side view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            },\n",
    "            {\n",
    "                \"attn_frames\": [15, 23],\n",
    "                \"clip_frames\": [16, 17, 18, 19, 20, 21, 22],\n",
    "                \"prompt\": \"(masterpiece, best quality, anime screencap, side view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            },\n",
    "            {\n",
    "                \"attn_frames\": [23, 31],\n",
    "                \"clip_frames\": [24, 25, 26, 27, 28, 29, 30],\n",
    "                \"prompt\": \"(masterpiece, best quality, anime screencap, back view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            },\n",
    "            {\n",
    "                \"attn_frames\": [31, 39],\n",
    "                \"clip_frames\": [32, 33, 34, 35, 36, 37, 38],\n",
    "                \"prompt\": \"(masterpiece, best quality, anime screencap, top view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            },\n",
    "            {\n",
    "                \"attn_frames\": [39, 47],\n",
    "                \"clip_frames\": [40, 41, 42, 43, 44, 45, 46],\n",
    "                \"prompt\": \"(masterpiece, best quality, anime screencap, bottom view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            },\n",
    "            {\n",
    "                \"attn_frames\": [47, 55],\n",
    "                \"clip_frames\": [48, 49, 50, 51, 52, 53, 54],\n",
    "                \"prompt\": \"(masterpiece, best quality, anime screencap, front view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            },\n",
    "            {\n",
    "                \"attn_frames\": [55, 63],\n",
    "                \"clip_frames\": [56, 57, 58, 59, 60, 61, 62],\n",
    "                \"prompt\": \"(masterpiece, best quality, anime screencap, back view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "realesrgan_conf = \"\"\"\n",
    "{\n",
    "    \"paths\": {\n",
    "        \"in_path\": \"../data/dataset/nerf/original/\",\n",
    "        \"out_path\": \"../data/dataset/nerf/train/\"\n",
    "    },\n",
    "    \"upscale\": {\n",
    "        \"outscale\": 4.0,\n",
    "        \"tile\": 192,\n",
    "        \"tile_pad\": 10,\n",
    "        \"pre_pad\": 10,\n",
    "        \"face_enhance\": true,\n",
    "        \"fp32\": false,\n",
    "        \"gpu_id\": 0\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"inference_controlvideo.json\", \"w\") as f:\n",
    "    f.write(controlvideo_conf)\n",
    "with open(\"inference_realesrgan.json\", \"w\") as f:\n",
    "    f.write(realesrgan_conf)\n",
    "controlvideo_conf = json.loads(controlvideo_conf)\n",
    "realesrgan_conf = json.loads(realesrgan_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python inference_controlvideo.py --settings_path \"inference_controlvideo.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python inference_realesrgan.py --settings_path \"inference_realesrgan.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images, save & display video\n",
    "images = sorted(glob.glob(os.path.join(realesrgan_conf[\"paths\"][\"out_path\"], \"*.png\")))\n",
    "images = [PIL.Image.open(image) for image in images]\n",
    "save_video(\n",
    "    8.0, images, 0.5, \"../ipynb/controlvideo_0.5x.mp4\", cv2.VideoWriter_fourcc(*\"MP4V\")\n",
    ")\n",
    "\n",
    "del images\n",
    "gc.collect()\n",
    "\n",
    "display_video(\"../ipynb/controlvideo_0.5x.mp4\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroundingDINO + SegmentAnything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundedsam_conf = \"\"\"\n",
    "{\n",
    "    \"paths\": {\n",
    "        \"in_path\": \"../data/dataset/nerf/train/\",\n",
    "        \"out_path\": \"../data/dataset/nerf/train/\",\n",
    "        \"cache_dir\": \"../data/checkpoints/\",\n",
    "        \"file_prefix\": \"dynamic_mask_\"\n",
    "    },\n",
    "    \"groundedsam\": {\n",
    "        \"device\": \"cuda\",\n",
    "        \"scale\": 0.5,\n",
    "        \"length\": 64,\n",
    "        \"clips\": [\n",
    "            {\n",
    "                \"clip_frames\": [0, 1, 2, 3, 4, 5, 6],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            },\n",
    "            {\n",
    "                \"clip_frames\": [7, 8, 9, 10, 11, 12, 13, 14],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            },\n",
    "            {\n",
    "                \"clip_frames\": [15, 16, 17, 18, 19, 20, 21, 22],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            },\n",
    "            {\n",
    "                \"clip_frames\": [23, 24, 25, 26, 27, 28, 29, 30],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            },\n",
    "            {\n",
    "                \"clip_frames\": [31, 32, 33, 34, 35, 36, 37, 38],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            },\n",
    "            {\n",
    "                \"clip_frames\": [39, 40, 41, 42, 43, 44, 45, 46],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            },\n",
    "            {\n",
    "                \"clip_frames\": [47, 48, 49, 50, 51, 52, 53, 54],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            },\n",
    "            {\n",
    "                \"clip_frames\": [55, 56, 57, 58, 59, 60, 61, 62, 63],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"inference_groundedsam.json\", \"w\") as f:\n",
    "    f.write(groundedsam_conf)\n",
    "groundedsam_conf = json.loads(groundedsam_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python inference_groundedsam.py --settings_file inference_groundedsam.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "images = sorted(glob.glob(os.path.join(realesrgan_conf[\"paths\"][\"out_path\"], \"*.png\")))\n",
    "images = [PIL.Image.open(image) for image in images]\n",
    "\n",
    "# Load masks\n",
    "masks = sorted(\n",
    "    glob.glob(\n",
    "        os.path.join(\n",
    "            groundedsam_conf[\"paths\"][\"out_path\"],\n",
    "            f\"{groundedsam_conf['paths']['file_prefix']}*.png\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "masks = [PIL.Image.open(mask) for mask in masks]\n",
    "\n",
    "# Create image strips\n",
    "image_strips = []\n",
    "for i, image in enumerate(images):\n",
    "    image = image_wrapper(image, \"pil\")\n",
    "    mask = image_wrapper(masks[i], \"pil\")\n",
    "    masked_image = image.to_np() * mask.to_np()\n",
    "    masked_image = image_wrapper(masked_image, \"np\")\n",
    "    image.concatenate(mask).concatenate(masked_image)\n",
    "    image = image.to_pil()\n",
    "    image_strips.append(image)\n",
    "\n",
    "save_video(\n",
    "    8.0,\n",
    "    image_strips,\n",
    "    0.5,\n",
    "    \"../ipynb/groundedsam_0.5x.mp4\",\n",
    "    cv2.VideoWriter_fourcc(*\"MP4V\"),\n",
    ")\n",
    "\n",
    "del images\n",
    "del masks\n",
    "del image_strips\n",
    "gc.collect()\n",
    "\n",
    "display_video(\"../ipynb/groundedsam_0.5x.mp4\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InstantNGP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%cd ../data/instant-ngp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = \"../dataset/nerf/\"\n",
    "save_snapshot = \"../dataset/nerf/instant-ngp.msgpack\"\n",
    "n_steps = 5000\n",
    "sharpen = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python scripts/run.py --training_data {training_data} --mode nerf --save_snapshot {save_snapshot} --n_steps {n_steps} --sharpen {sharpen}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rendering camera path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_camera_path = \"../dataset/nerf/base_cam.json\"\n",
    "video_fps = 8\n",
    "video_n_seconds = 8\n",
    "video_spp = 16\n",
    "video_output = \"../../ipynb/instant-ngp.mp4\"\n",
    "width, height = 2304, 2304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python scripts/run.py --mode nerf --load_snapshot {save_snapshot} --video_camera_path {video_camera_path} --video_fps {video_fps} --video_n_seconds {video_n_seconds} --video_spp {video_spp} --video_output {video_output} --width {width} --height {height} --sharpen {sharpen}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_video(video_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mesh extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mesh = \"../dataset/nerf/instant-ngp.obj\"\n",
    "marching_cubes_res = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python scripts/run.py --mode nerf --load_snapshot {save_snapshot} --save_mesh {save_mesh} --marching_cubes_res {marching_cubes_res} --sharpen {sharpen}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marching-waifu-x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
