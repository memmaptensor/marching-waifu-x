{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ControlVideo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!git clone --recurse-submodules https://github.com/rossiyareich/marching-waifu-x.git\n",
    "%cd marching-waifu-x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only for local install (run `setup-n.sh` or `setup.bat` and `huggingface-cli login` beforehand!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%cd ../"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "# Install requirements\n",
    "!python -m pip install -r requirements.txt\n",
    "!python -m pip install -r ext/Real-ESRGAN/requirements.txt\n",
    "\n",
    "# Create directories\n",
    "!mkdir data/dataset/nerf/original/\n",
    "!mkdir data/dataset/nerf/train/\n",
    "\n",
    "# Install local packages\n",
    "%cd ext/Real-ESRGAN/\n",
    "!python setup.py develop\n",
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%cd scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlvideo = \"\"\"\n",
    "--out_path \"../data/dataset/nerf/original/\"\n",
    "--sd_repo \"rossiyareich/Nabylon-v1.0-fp16\"\n",
    "--vae_repo \"stabilityai/sd-vae-ft-mse\"\n",
    "--controlnet_repo \"lllyasviel/control_v11p_sd15_openpose\"\n",
    "--ifnet_path \"../data/checkpoints/flownet.pkl\"\n",
    "--cache_dir \"../data/checkpoints/\"\n",
    "--prompt \"(masterpiece, best quality)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\"\n",
    "--negative_prompt \"EasyNegative, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "--textual_inversion_path \"../data/embeddings/\"\n",
    "--controlnet_conditioning_path \"../data/dataset/conditioning/\" \n",
    "--video_length 16\n",
    "--num_inference_steps 25\n",
    "--guidance_scale 10.0\n",
    "--smoother_steps \"20,21\"\n",
    "--window_size -1\n",
    "--controlnet_conditioning_scale 1.0\n",
    "--seed -1\n",
    "\"\"\".replace(\n",
    "    \"\\n\", \" \"\n",
    ")\n",
    "\n",
    "realesrgan = \"\"\"\n",
    "--in_path \"../data/dataset/nerf/original/\"\n",
    "--out_path \"../data/dataset/nerf/train/\"\n",
    "--outscale 4.0\n",
    "--tile_pad 192\n",
    "--pre_pad 16\n",
    "--face_enhance True\n",
    "--fp32 False\n",
    "--gpu_id 0\n",
    "\"\"\".replace(\n",
    "    \"\\n\", \" \"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "import PIL.Image\n",
    "from src.utils.image_wrapper import *\n",
    "\n",
    "\n",
    "def get_args(switches):\n",
    "    args = switches.split(\"--\")[1:]\n",
    "    args = [arg.strip() for arg in args]\n",
    "    args = [arg.split(\" \", 1) for arg in args]\n",
    "    args = [arg[1].replace('\"', \"\") for arg in args]\n",
    "    return dict(tuple(args))\n",
    "\n",
    "\n",
    "def load_images(max_len):\n",
    "    video_frames = []\n",
    "    controlnet_conditions = []\n",
    "    for filepath in sorted(glob.glob(\"../data/dataset/conditioning/*.png\"))[max_len:]:\n",
    "        pl = pathlib.Path(filepath)\n",
    "        video_frame_path = os.path.join(\n",
    "            \"../data/dataset/nerf/original/\", f\"{pl.stem}.png\"\n",
    "        )\n",
    "        video_frames.append(PIL.Image.open(video_frame_path))\n",
    "        controlnet_conditions.append(PIL.Image.open(filepath))\n",
    "    return (video_frames, controlnet_conditions)\n",
    "\n",
    "\n",
    "def display_at_index(index, video_frames, controlnet_conditions):\n",
    "    display(\n",
    "        image_wrapper(video_frames[index], \"pil\")\n",
    "        .concatenate(image_wrapper(controlnet_conditions[index], \"pil\"))\n",
    "        .to_pil()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python inference_controlvideo.py {controlvideo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid = 0\n",
    "\n",
    "controlvideo_args = get_args(controlvideo)\n",
    "video_frames, controlnet_conditions = load_images(controlvideo_args[\"video_length\"])\n",
    "display_at_index(fid, video_frames, controlnet_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python inference_realesrgan.py {realesrgan}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marching-waifu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
