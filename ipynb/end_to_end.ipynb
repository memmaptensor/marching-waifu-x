{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ControlVideo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!git clone --recurse-submodules https://github.com/rossiyareich/marching-waifu-x.git\n",
    "%cd marching-waifu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only for local install (run `setup.sh` or `setup.bat` and `huggingface-cli login` beforehand!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%cd ../"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "# Install requirements\n",
    "!python -m pip install -r requirements.txt\n",
    "!python -m pip install -r ext/Real-ESRGAN/requirements.txt\n",
    "\n",
    "# Create directories\n",
    "!mkdir data/dataset/nerf/original/\n",
    "!mkdir data/dataset/nerf/train/\n",
    "\n",
    "# Install local packages\n",
    "%cd ext/Real-ESRGAN/\n",
    "!python setup.py develop\n",
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%cd scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Inference configuration\n",
    "class config(object):\n",
    "    pass\n",
    "\n",
    "#@markdown ###**ControlVideo paths**\n",
    "controlvideo = config()\n",
    "controlvideo.out_path = \"../data/dataset/nerf/original/\"  #@param {type:\"string\"}\n",
    "controlvideo.sd_repo = \"rossiyareich/Nabylon-v1.0-fp16\"  #@param {type:\"string\"}\n",
    "controlvideo.vae_repo = \"stabilityai/sd-vae-ft-mse\"  #@param {type:\"string\"}\n",
    "controlvideo.controlnet_repo = \"lllyasviel/control_v11p_sd15_openpose\"  #@param {type:\"string\"}\n",
    "controlvideo.ifnet_path = \"../data/checkpoints/flownet.pkl\"  #@param {type:\"string\"}\n",
    "controlvideo.cache_dir = \"../data/checkpoints/\"  #@param {type:\"string\"}\n",
    "#@markdown ###**ControlVideo**\n",
    "controlvideo.prompt = \"(masterpiece, best quality)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\"  #@param {type:\"string\"}\n",
    "controlvideo.negative_prompt = \"EasyNegative, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"  #@param {type:\"string\"}\n",
    "controlvideo.textual_inversion_path = \"../data/embeddings/\"  #@param {type:\"string\"}\n",
    "controlvideo.controlnet_conditioning_path = \"../data/dataset/conditioning/\"  #@param {type:\"string\"}\n",
    "controlvideo.video_length = 15  #@param {type:\"slider\", min:1, max:250, step:1}\n",
    "controlvideo.num_inference_steps = 50  #@param {type:\"slider\", min:1, max:200, step:1}\n",
    "controlvideo.guidance_scale = 10  #@param {type:\"slider\", min:1, max:50, step:0.5}\n",
    "controlvideo.smoother_stpes = \"19,20\"  #@param {type:\"string\"}\n",
    "controlvideo.window_size = None  #@param {type:\"raw\"}\n",
    "controlvideo.controlnet_conditioning_scale = 1.0  #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
    "controlvideo.seed = None  #@param {type:\"raw\"}\n",
    "\n",
    "#@markdown ###**RealESRGAN**\n",
    "realesrgan = config()\n",
    "realesrgan.in_path = controlvideo.out_path\n",
    "realesrgan.out_path = \"../data/dataset/nerf/train/\"  #@param {type:\"string\"}\n",
    "realesrgan.outscale = 4.0  #@param {type:\"slider\", min:1, max:200, step:1}\n",
    "realesrgan.tile = 192  #@param {type:\"slider\", min:1, max:200, step:1}\n",
    "realesrgan.tile_pad = 16  #@param {type:\"slider\", min:1, max:200, step:1}\n",
    "realesrgan.pre_pad = 16  #@param {type:\"slider\", min:1, max:200, step:1}\n",
    "realesrgan.face_enhance = True  #@param {type:\"boolean\"}\n",
    "realesrgan.fp32 = False  #@param {type:\"boolean\"}\n",
    "realesrgan.gpu_id = 0  #@param {type:\"slider\", min:1, max:200, step:1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "import PIL.Image\n",
    "from src.utils.image_wrapper import *\n",
    "\n",
    "def load_images():\n",
    "    video_frames = []\n",
    "    controlnet_conditions = []\n",
    "    for filepath in sorted(\n",
    "        glob.glob(os.path.combine(controlvideo.controlnet_conditioning_path, \"*.png\"))\n",
    "    ):\n",
    "        pl = pathlib.Path(filepath)\n",
    "        video_frame_path = os.path.combine(controlvideo.out_path, pl.stem, \".png\")\n",
    "        video_frames.append(PIL.Image.open(video_frame_path))\n",
    "        controlnet_conditions.append(PIL.Image.open(filepath))\n",
    "    return (video_frames, controlnet_conditions)\n",
    "\n",
    "def display_at_index(index, video_frames, controlnet_conditions):\n",
    "    display(image_wrapper(video_frames[index], \"pil\").concatenate(\n",
    "        image_wrapper(controlnet_conditions[index], \"pil\")\n",
    "    ).to_pil())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python inference_controlvideo.py \\ \n",
    "    --out_path {controlvideo.out_path} \\ \n",
    "    --sd_repo {controlvideo.sd_repo} \\\n",
    "    --vae_repo {controlvideo.vae_repo} \\ \n",
    "    --controlnet_repo {controlvideo.controlnet_repo} \\ \n",
    "    --ifnet_path {controlvideo.ifnet_path} \\\n",
    "    --cache_dir {controlvideo.cache_dir} \\\n",
    "    --prompt {controlvideo.prompt} \\\n",
    "    --negative_prompt {controlvideo.negative_prompt} \\\n",
    "    --textual_inversion_path {controlvideo.textual_inversion_path} \\\n",
    "    --controlnet_conditioning_path {controlvideo.controlnet_conditioning_path} \\\n",
    "    --video_length {controlvideo.video_length} \\\n",
    "    --num_inference_steps {controlvideo.num_inference_steps} \\\n",
    "    --guidance_scale {controlvideo.guidance_scale} \\\n",
    "    --smoother_steps {controlvideo.smoother_steps} \\\n",
    "    --window_size {controlvideo.window_size} \\\n",
    "    --controlnet_conditioning_scale {controlvideo.controlnet_conditioning_scale} \\ \n",
    "    --seed {controlvideo.seed} \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "display_interval = 1\n",
    "\n",
    "video_frames, controlnet_conditions = load_images()\n",
    "length = len(video_frames)\n",
    "\n",
    "for i in range(length):\n",
    "    display_at_index(i, video_frames, controlnet_conditions)\n",
    "    time.sleep(display_interval)\n",
    "    if i < length - 1:\n",
    "        clear_output(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python inference_realesrgan.py \\\n",
    "    --in_path {realesrgan.in_path} \\\n",
    "    --out_path {realesrgan.out_path} \\\n",
    "    --outscale {realesrgan.outscale} \\\n",
    "    --tile_pad {realesrgan.tile_pad} \\\n",
    "    --pre_pad {realesrgan.pre_pad} \\\n",
    "    --face_enhance {realesrgan.face_enhance} \\\n",
    "    --fp32 {realesrgan.fp32} \\\n",
    "    --gpu_id {realesrgan.gpu_id} \\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marching-waifu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
