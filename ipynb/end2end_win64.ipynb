{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `conda run -n marching-waifu-x --no-capture-output setup.bat` (once) beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Setup torch and other prerequisites\n",
    "%cd ..\n",
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install gdown ipykernel ipywidgets\n",
    "!python -m pip install torch torchvision torchaudio torchtext torchdata --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Update submodules\n",
    "!git submodule update --init --recursive\n",
    "\n",
    "# Create directories\n",
    "!mkdir data/dataset/nvdiffrec/original\n",
    "!mkdir data/dataset/nvdiffrec/upscaled\n",
    "!mkdir data/dataset/nvdiffrec/train\n",
    "\n",
    "# Install requirements\n",
    "!python -m pip install -r requirements.txt\n",
    "\n",
    "# Setup RealESRGAN\n",
    "%cd ext/Real-ESRGAN\n",
    "!python -m pip install -r requirements.txt\n",
    "!python setup.py develop\n",
    "%cd ../..\n",
    "\n",
    "# Setup SegmentAnything, GroundingDINO\n",
    "%cd ext/Grounded-Segment-Anything\n",
    "!python -m pip install -e segment_anything\n",
    "!python -m pip install -e GroundingDINO\n",
    "%cd grounded-sam-osx\n",
    "!python -m pip install openmim\n",
    "!mim install mmcv-full\n",
    "!python -m pip install -r requirements.txt\n",
    "%cd transformer_utils\n",
    "!python setup.py install\n",
    "%cd ../../../..\n",
    "!python -m pip install timm transformers fairscale pycocoevalcap scipy\n",
    "!python -m pip install pycocotools onnxruntime onnx\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%cd scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import PIL.Image\n",
    "from IPython.display import Video\n",
    "\n",
    "from src.utils.image_wrapper import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ControlVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video(fps, images, scale, video_path, fourcc):\n",
    "    images = [image_wrapper(image).scale(scale).to_cv2() for image in images]\n",
    "    video = cv2.VideoWriter(video_path, fourcc, fps, images[0].size)\n",
    "    for image in images:\n",
    "        video.write(image)\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def display_video(video_path):\n",
    "    Video.from_file(video_path, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlvideo_conf = \"\"\"\n",
    "{\n",
    "    \"paths\": {\n",
    "        \"out_path\": \"../data/dataset/nvdiffrec/original/\",\n",
    "        \"cache_dir\": \"../data/checkpoints/\",\n",
    "        \"ifnet_path\": \"../data/checkpoints/flownet.pkl\",\n",
    "        \"condition_path\": \"../data/dataset/conditioning/\",\n",
    "        \"textual_inversion_path\": \"../data/embeddings/\"\n",
    "    },\n",
    "    \"repositories\": {\n",
    "        \"sd\": \"rossiyareich/aniflatmixAnimeFlatColorStyle_v20-fp16\",\n",
    "        \"vae\": \"rossiyareich/anything-v4.0-vae\"\n",
    "    },\n",
    "    \"controlnet\": {\n",
    "        \"scales\": [1.0, 0.85, 0.85],\n",
    "        \"exp\": 0.85,\n",
    "        \"pipe\": {\n",
    "            \"openpose_full\": \"lllyasviel/control_v11p_sd15_openpose\",\n",
    "            \"depth\": \"lllyasviel/control_v11f1p_sd15_depth\",\n",
    "            \"normals\": \"lllyasviel/control_v11p_sd15_normalbae\"\n",
    "        }\n",
    "    },\n",
    "    \"video\": {\n",
    "        \"num_inference_steps\": 20,\n",
    "        \"guidance_scale\": 8.0,\n",
    "        \"smooth_steps\": [14, 15],\n",
    "        \"seed\": null,\n",
    "        \"same_frame_noise\": false,\n",
    "        \"length\": 80,\n",
    "        \"keyframes\": {\n",
    "            \"frames\": [0, 9, 19, 29, 39, 49, 59, 69, 79],\n",
    "            \"prompt\": \"(masterpiece, best quality, character sheet)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "            \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "        },\n",
    "        \"clips\": [\n",
    "            {\n",
    "                \"attn_frames\": [0, 9],\n",
    "                \"clip_frames\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                \"prompt\": \"(masterpiece, best quality, character sheet, front view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            },\n",
    "            {\n",
    "                \"attn_frames\": [9, 19],\n",
    "                \"clip_frames\": [10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
    "                \"prompt\": \"(masterpiece, best quality, character sheet, front view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            },\n",
    "            {\n",
    "                \"attn_frames\": [19, 29],\n",
    "                \"clip_frames\": [20, 21, 22, 23, 24, 25, 26, 27, 28],\n",
    "                \"prompt\": \"(masterpiece, best quality, character sheet, side view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            },\n",
    "            {\n",
    "                \"attn_frames\": [29, 39],\n",
    "                \"clip_frames\": [30, 31, 32, 33, 34, 35, 36, 37, 38],\n",
    "                \"prompt\": \"(masterpiece, best quality, character sheet, side view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            },\n",
    "            {\n",
    "                \"attn_frames\": [39, 49],\n",
    "                \"clip_frames\": [40, 41, 42, 43, 44, 45, 46, 47, 48],\n",
    "                \"prompt\": \"(masterpiece, best quality, character sheet, back view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            },\n",
    "            {\n",
    "                \"attn_frames\": [49, 59],\n",
    "                \"clip_frames\": [50, 51, 52, 53, 54, 55, 56, 57, 58],\n",
    "                \"prompt\": \"(masterpiece, best quality, character sheet, back view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            },\n",
    "            {\n",
    "                \"attn_frames\": [59, 69],\n",
    "                \"clip_frames\": [60, 61, 62, 63, 64, 65, 66, 67, 68],\n",
    "                \"prompt\": \"(masterpiece, best quality, character sheet, side view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            },\n",
    "            {\n",
    "                \"attn_frames\": [69, 79],\n",
    "                \"clip_frames\": [70, 71, 72, 73, 74, 75, 76, 77, 78],\n",
    "                \"prompt\": \"(masterpiece, best quality, character sheet, side view)+, 1girl, white hoodie, earmuffs, leggings, white scarf, black gloves, white socks, short blue hair, blue eyes, bangs\",\n",
    "                \"negative_prompt\": \"easynegative, badhandv4, verybadimagenegative_v1.3, (worst quality, low quality, logo, text, watermark, username, nsfw), inaccurate hands and fingers\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "realesrgan_conf = \"\"\"\n",
    "{\n",
    "    \"paths\": {\n",
    "        \"in_path\": \"../data/dataset/nvdiffrec/original/\",\n",
    "        \"out_path\": \"../data/dataset/nvdiffrec/upscaled/\"\n",
    "    },\n",
    "    \"upscale\": {\n",
    "        \"outscale\": 4.0,\n",
    "        \"tile\": 192,\n",
    "        \"tile_pad\": 10,\n",
    "        \"pre_pad\": 10,\n",
    "        \"face_enhance\": true,\n",
    "        \"fp32\": false,\n",
    "        \"gpu_id\": 0\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"inference_controlvideo.json\", \"w\") as f:\n",
    "    f.write(controlvideo_conf)\n",
    "with open(\"inference_realesrgan.json\", \"w\") as f:\n",
    "    f.write(realesrgan_conf)\n",
    "controlvideo_conf = json.loads(controlvideo_conf)\n",
    "realesrgan_conf = json.loads(realesrgan_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python inference_controlvideo.py --settings_path \"inference_controlvideo.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python inference_realesrgan.py --settings_path \"inference_realesrgan.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images, save & display video\n",
    "images = sorted(glob.glob(os.path.join(realesrgan_conf[\"paths\"][\"out_path\"], \"*.png\")))\n",
    "images = [PIL.Image.open(image) for image in images]\n",
    "save_video(\n",
    "    10.0, images, 0.5, \"../ipynb/controlvideo_0.5x.mp4\", cv2.VideoWriter_fourcc(*\"MP4V\")\n",
    ")\n",
    "\n",
    "del images\n",
    "gc.collect()\n",
    "\n",
    "display_video(\"../ipynb/controlvideo_0.5x.mp4\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroundingDINO + SegmentAnything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundedsam_conf = \"\"\"\n",
    "{\n",
    "    \"paths\": {\n",
    "        \"in_path\": \"../data/dataset/nvdiffrec/upscaled/\",\n",
    "        \"out_path\": \"../data/dataset/nvdiffrec/train/\",\n",
    "        \"cache_dir\": \"../data/checkpoints/\"\n",
    "    },\n",
    "    \"groundedsam\": {\n",
    "        \"device\": \"cuda\",\n",
    "        \"scale\": 0.5,\n",
    "        \"length\": 80,\n",
    "        \"clips\": [\n",
    "            {\n",
    "                \"clip_frames\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            },\n",
    "            {\n",
    "                \"clip_frames\": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            },\n",
    "            {\n",
    "                \"clip_frames\": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            },\n",
    "            {\n",
    "                \"clip_frames\": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            },\n",
    "            {\n",
    "                \"clip_frames\": [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            },\n",
    "            {\n",
    "                \"clip_frames\": [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            },\n",
    "            {\n",
    "                \"clip_frames\": [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            },\n",
    "            {\n",
    "                \"clip_frames\": [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
    "                \"det_prompt\": \"girl\",\n",
    "                \"box_threshold\": 0.3,\n",
    "                \"text_threshold\": 0.25,\n",
    "                \"merge_masks\": true\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"inference_groundedsam.json\", \"w\") as f:\n",
    "    f.write(groundedsam_conf)\n",
    "groundedsam_conf = json.loads(groundedsam_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python inference_groundedsam.py --settings_file inference_groundedsam.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "images = sorted(glob.glob(os.path.join(realesrgan_conf[\"paths\"][\"out_path\"], \"*.png\")))\n",
    "images = [PIL.Image.open(image) for image in images]\n",
    "\n",
    "# Load masked images\n",
    "masked_images = sorted(\n",
    "    glob.glob(\n",
    "        os.path.join(\n",
    "            groundedsam_conf[\"paths\"][\"out_path\"],\n",
    "            f\"{groundedsam_conf['paths']['file_prefix']}*.png\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "masked_images = [PIL.Image.open(masked) for masked in masked_images]\n",
    "\n",
    "# Create image strips\n",
    "image_strips = []\n",
    "for i, image in enumerate(images):\n",
    "    image = image_wrapper(image, \"pil\")\n",
    "    masked_image = image_wrapper(masked_images[i], \"pil\")\n",
    "    image.concatenate(masked_image)\n",
    "    image_strips.append(image.to_pil())\n",
    "\n",
    "save_video(\n",
    "    10.0,\n",
    "    image_strips,\n",
    "    0.5,\n",
    "    \"../ipynb/groundedsam_0.5x.mp4\",\n",
    "    cv2.VideoWriter_fourcc(*\"MP4V\"),\n",
    ")\n",
    "\n",
    "del images\n",
    "del masked_images\n",
    "del image_strips\n",
    "gc.collect()\n",
    "\n",
    "display_video(\"../ipynb/groundedsam_0.5x.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marching-waifu-x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
